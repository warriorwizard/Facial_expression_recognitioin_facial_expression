{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from zipfile import ZipFile\r\n",
    "file_name = \"/content/drive/MyDrive/archive.zip\"\r\n",
    "\r\n",
    "with ZipFile(file_name, 'r') as zip:\r\n",
    "  zip.extractall()\r\n",
    "  print(\"Done\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/archive.zip'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/674792808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/archive.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/archive.zip'"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T16:07:08.432129Z",
     "iopub.status.busy": "2021-09-16T16:07:08.431183Z",
     "iopub.status.idle": "2021-09-16T16:07:08.505163Z",
     "shell.execute_reply": "2021-09-16T16:07:08.504006Z",
     "shell.execute_reply.started": "2021-09-16T16:02:02.007756Z"
    },
    "id": "Meh9wc4zdoQT",
    "outputId": "158918e4-5143-4673-d897-6189edec6ff9",
    "papermill": {
     "duration": 0.101207,
     "end_time": "2021-09-16T16:07:08.505543",
     "exception": true,
     "start_time": "2021-09-16T16:07:08.404336",
     "status": "failed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import cv2\r\n",
    "# !pip install tensorflow\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\r\n",
    "from tensorflow.keras.layers import Conv2D\r\n",
    "\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras.layers import MaxPooling2D\r\n",
    "!pip install nltk\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T16:02:13.568793Z",
     "iopub.status.busy": "2021-09-16T16:02:13.568451Z",
     "iopub.status.idle": "2021-09-16T16:02:43.093129Z",
     "shell.execute_reply": "2021-09-16T16:02:43.091943Z",
     "shell.execute_reply.started": "2021-09-16T16:02:13.568757Z"
    },
    "id": "tT9qRwU8U5hc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "metadata": {
    "id": "ZSCG3TPfd5dB",
    "outputId": "88bbc0cf-996d-446f-95d0-b431a4713ab3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_dir = '../input/fer2013/train'\r\n",
    "val_dir = '../input/fer2013/test'\r\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "        train_dir,\r\n",
    "        target_size=(48,48),\r\n",
    "        batch_size=64,\r\n",
    "        color_mode=\"grayscale\",\r\n",
    "        class_mode='categorical')\r\n",
    "\r\n",
    "validation_generator = val_datagen.flow_from_directory(\r\n",
    "        val_dir,\r\n",
    "        target_size=(48,48),\r\n",
    "        batch_size=64,\r\n",
    "        color_mode=\"grayscale\",\r\n",
    "        class_mode='categorical')"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T16:02:43.096417Z",
     "iopub.status.busy": "2021-09-16T16:02:43.095951Z",
     "iopub.status.idle": "2021-09-16T16:02:44.595941Z",
     "shell.execute_reply": "2021-09-16T16:02:44.595272Z",
     "shell.execute_reply.started": "2021-09-16T16:02:43.096364Z"
    },
    "id": "S92aXPw8ouRb",
    "outputId": "a2b4967d-a642-482c-bdad-5d73f9cf1af9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emotion_model = Sequential()\r\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\r\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\r\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "emotion_model.add(Dropout(0.25))\r\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "emotion_model.add(Dropout(0.25))\r\n",
    "emotion_model.add(Flatten())\r\n",
    "emotion_model.add(Dense(1024, activation='relu'))\r\n",
    "emotion_model.add(Dropout(0.5))\r\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T16:02:51.447794Z",
     "iopub.status.busy": "2021-09-16T16:02:51.447449Z",
     "iopub.status.idle": "2021-09-16T16:02:51.556311Z",
     "shell.execute_reply": "2021-09-16T16:02:51.555369Z",
     "shell.execute_reply.started": "2021-09-16T16:02:51.447749Z"
    },
    "id": "t74GyVFJU5zy",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\r\n",
    "emotion_model_info = emotion_model.fit_generator(\r\n",
    "        train_generator,\r\n",
    "    \r\n",
    "        steps_per_epoch=28709 // 64,\r\n",
    "        epochs=50,\r\n",
    "        validation_data=validation_generator,\r\n",
    "        validation_steps=7178 // 64)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-16T16:04:05.718396Z",
     "iopub.status.busy": "2021-09-16T16:04:05.718073Z",
     "iopub.status.idle": "2021-09-16T16:04:38.793503Z",
     "shell.execute_reply": "2021-09-16T16:04:38.792208Z",
     "shell.execute_reply.started": "2021-09-16T16:04:05.718365Z"
    },
    "id": "ndB4aIimU5o3",
    "outputId": "978ff4d3-994b-4486-d206-ec2eb5d67ec7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Saving the model\r\n",
    "emotion_model.save('model.h5')"
   ],
   "outputs": [],
   "metadata": {
    "id": "udLyFoZ7XiW9",
    "outputId": "752ff6e6-ec7b-4de5-ba31-09ed3e9050a0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import load_model\r\n",
    "emotion_model = load_model('model.h5')"
   ],
   "outputs": [],
   "metadata": {
    "id": "OpqMYqG_M4oV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def emotion_analysis(emotions):\r\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\r\n",
    "    y_pos = np.arange(len(objects))\r\n",
    "    \r\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\r\n",
    "    plt.xticks(y_pos, objects)\r\n",
    "    plt.ylabel('percentage')\r\n",
    "    plt.title('emotion')\r\n",
    "    \r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "pazcXGdiM8v_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#CODE for Capturing an image on Colab from here: https://colab.research.google.com/notebook#fileId=1OnUy6eFE7XhdfGfAHDCqQxpwueTOj_NO\r\n",
    "\r\n",
    "from IPython.display import display, Javascript\r\n",
    "from google.colab.output import eval_js\r\n",
    "from base64 import b64decode\r\n",
    "\r\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\r\n",
    "  js = Javascript('''\r\n",
    "    async function takePhoto(quality) {\r\n",
    "      const div = document.createElement('div');\r\n",
    "      const capture = document.createElement('button');\r\n",
    "      capture.textContent = 'Capture';\r\n",
    "      div.appendChild(capture);\r\n",
    "\r\n",
    "      const video = document.createElement('video');\r\n",
    "      video.style.display = 'block';\r\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\r\n",
    "\r\n",
    "      document.body.appendChild(div);\r\n",
    "      div.appendChild(video);\r\n",
    "      video.srcObject = stream;\r\n",
    "      await video.play();\r\n",
    "\r\n",
    "      // Resize the output to fit the video element.\r\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\r\n",
    "\r\n",
    "      // Wait for Capture to be clicked.\r\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\r\n",
    "\r\n",
    "      const canvas = document.createElement('canvas');\r\n",
    "      canvas.width = video.videoWidth;\r\n",
    "      canvas.height = video.videoHeight;\r\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\r\n",
    "      stream.getVideoTracks()[0].stop();\r\n",
    "      div.remove();\r\n",
    "      return canvas.toDataURL('image/jpeg', quality);\r\n",
    "    }\r\n",
    "    ''')\r\n",
    "  display(js)\r\n",
    "  data = eval_js('takePhoto({})'.format(quality))\r\n",
    "  binary = b64decode(data.split(',')[1])\r\n",
    "  with open(filename, 'wb') as f:\r\n",
    "    f.write(binary)\r\n",
    "  return filename"
   ],
   "outputs": [],
   "metadata": {
    "id": "_3hXn_ASNO0V",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "take_photo()"
   ],
   "outputs": [],
   "metadata": {
    "id": "ELxE3d9nwjjm",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import cv2\r\n",
    "            \r\n",
    "# def facecrop(image):  \r\n",
    "#     facedata = '/content/haarcascade_frontalface_alt.xml'\r\n",
    "#     cascade = cv2.CascadeClassifier(facedata)\r\n",
    "\r\n",
    "#     img = cv2.imread(image)\r\n",
    "\r\n",
    "#     try:\r\n",
    "    \r\n",
    "#         minisize = (img.shape[1],img.shape[0])\r\n",
    "#         miniframe = cv2.resize(img, minisize)\r\n",
    "\r\n",
    "#         faces = cascade.detectMultiScale(miniframe)\r\n",
    "\r\n",
    "#         for f in faces:\r\n",
    "#             x, y, w, h = [ v for v in f ]\r\n",
    "#             cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\r\n",
    "\r\n",
    "#             sub_face = img[y:y+h, x:x+w]\r\n",
    "\r\n",
    "            \r\n",
    "#             cv2.imwrite('capture.jpg', sub_face)\r\n",
    "#             #print (\"Writing: \" + image)\r\n",
    "\r\n",
    "#     except Exception as e:\r\n",
    "#         print (e)\r\n",
    "\r\n",
    "   \r\n",
    "\r\n",
    "\r\n",
    "# if __name__ == '__main__':\r\n",
    "#     facecrop('/content/photo.jpg')\r\n",
    "\r\n",
    "# #Testing a file.\r\n",
    "\r\n",
    "# from keras.preprocessing import image\r\n",
    "# from keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "# import numpy as np\r\n",
    "# import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "\r\n",
    "# file = '/content/capture.jpg'\r\n",
    "# true_image = image.load_img(file)\r\n",
    "# img = image.load_img(file, color_mode=\"grayscale\", target_size=(48, 48))\r\n",
    "\r\n",
    "# x = image.img_to_array(img)\r\n",
    "# x = np.expand_dims(x, axis = 0)\r\n",
    "\r\n",
    "# x /= 255\r\n",
    "\r\n",
    "# custom = emotion_model.predict(x)\r\n",
    "# emotion_analysis(custom[0])\r\n",
    "\r\n",
    "# x = np.array(x, 'float32')\r\n",
    "# x = x.reshape([48, 48]);\r\n",
    "\r\n",
    "\r\n",
    "# plt.imshow(true_image)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "QMyrDnhWX_Zj",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "id": "rF8p4ybgoflu",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.513712,
   "end_time": "2021-09-16T16:07:09.027213",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-16T16:07:00.513501",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}